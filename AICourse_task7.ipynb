{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOveSDUyDsIHyRIUu5SMnKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zendellll/Road2_AI_Course/blob/main/AICourse_task7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqPqHErhwF-D",
        "outputId": "fb9ec8db-ae1c-4c8c-e1d6-da18024213f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds\n",
        "!mkdir /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/images\n",
        "!mkdir /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/labels\n",
        "\n",
        "!cp /content/drive/MyDrive/drone_data/*.jpg /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/images\n",
        "!cp /content/drive/MyDrive/drone_data/*.txt /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/labels\n",
        "!cp /content/drive/MyDrive/bird_data/*.jpg /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/images\n",
        "!cp /content/drive/MyDrive/bird_data/*.txt /content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/labels"
      ],
      "metadata": {
        "id": "r_1weAEl3mPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def augment_image(image):\n",
        "    # Convert image to PyTorch tensor\n",
        "    image_tensor = transforms.ToTensor()(image)\n",
        "\n",
        "    # Randomly choose an augmentation\n",
        "    augmentation_type = random.choice(['flip', 'color_jitter', 'rotation'])\n",
        "\n",
        "    # Apply random flip\n",
        "    if augmentation_type == 'flip':\n",
        "        image_tensor = transforms.RandomHorizontalFlip()(image_tensor)\n",
        "\n",
        "    # Apply random color jitter\n",
        "    elif augmentation_type == 'color_jitter':\n",
        "        image_tensor = transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2)(image_tensor)\n",
        "\n",
        "    # Apply random rotation\n",
        "    elif augmentation_type == 'rotation':\n",
        "        angle = random.uniform(-15, 15)\n",
        "        image_tensor = transforms.functional.rotate(image_tensor, angle)\n",
        "\n",
        "    # Convert back to PIL Image\n",
        "    augmented_image = transforms.ToPILImage()(image_tensor)\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "# Function to convert YOLO coordinates to bounding box coordinates\n",
        "def yolo_to_bbox(image_shape, class_index, x_center, y_center, width, height):\n",
        "    img_height, img_width, _ = image_shape\n",
        "\n",
        "    x_min = int((x_center - width / 2) * img_width)\n",
        "    y_min = int((y_center - height / 2) * img_height)\n",
        "    x_max = int((x_center + width / 2) * img_width)\n",
        "    y_max = int((y_center + height / 2) * img_height)\n",
        "\n",
        "    return x_min, y_min, x_max, y_max\n",
        "\n",
        "# Function to randomly crop a 32x32 section from the image\n",
        "def random_crop(image, crop_size=(32, 32)):\n",
        "    img_height, img_width, _ = image.shape\n",
        "\n",
        "    # Randomly choose the top-left corner of the crop\n",
        "    y_start = np.random.randint(0, img_height - crop_size[0] + 1)\n",
        "    x_start = np.random.randint(0, img_width - crop_size[1] + 1)\n",
        "\n",
        "    # Crop the image\n",
        "    cropped_img = image[y_start:y_start + crop_size[0], x_start:x_start + crop_size[1]]\n",
        "\n",
        "    return cropped_img"
      ],
      "metadata": {
        "id": "bB_03msU9GAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-process data\n",
        "## Prompt:\n",
        "Today we are doing some AI coding on Google Colab, using Python, Keras, TensorFlow.\n",
        "\n",
        "I have a dataset containing images of either birds or drones. All images are found in path - '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/images', and all labels are found in - '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/labels'. In the images dir, there are images of both birds and drones. Each image has a corresponding label file, which has the same name, and ends with .txt instead of .jpg.\n",
        "All labels are in the YOLO annotation format. the class IDs are 0 for drone and 1 for bird.\n",
        "\n",
        "I need you to go over all images in the image path I provided. For each image, start by cropping a random 32*32 area. Run the cropped image through the augmentation function to get an augmented image. Then, save that image into the path 'content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/images', and save a corresponding label file at '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/labels'. For the random crop image, the label should be 2 (the .txt file should have only '2' in it).\n",
        "Then, using the coordinates from the label file, extract the object location and crop around the object. Take the cropped object and resize it to 32*32. Run it through the augmentation function. Once done, I need you to save the image. The location is based on the label file.\n",
        "If the first number in the label file is '0', it means the object is a drone, in which case we will save the image at '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/images' and save a corresponding label at '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/labels' - the label file containing only a '0'.\n",
        "Else (meaning the first number in the label file is '1'), the object is a bird. Then we will save it in '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/images', and save a corresponding label file at '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/labels' - with the label file containing only a '1'."
      ],
      "metadata": {
        "id": "v6ELWSpAoAxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path definitions\n",
        "image_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/images'\n",
        "label_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/labels'\n",
        "\n",
        "# Output paths\n",
        "other_image_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/images'\n",
        "other_label_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/labels'\n",
        "\n",
        "drone_image_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/images'\n",
        "drone_label_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/labels'\n",
        "\n",
        "bird_image_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/images'\n",
        "bird_label_path = '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/labels'"
      ],
      "metadata": {
        "id": "Pdsm07LhrM3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each image\n",
        "for filename in os.listdir(image_path):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        # Load the image\n",
        "        img = cv2.imread(os.path.join(image_path, filename))\n",
        "\n",
        "        # Load corresponding label file\n",
        "        label_filename = os.path.splitext(filename)[0] + '.txt'\n",
        "        label_file_path = os.path.join(label_path, label_filename)\n",
        "\n",
        "        with open(label_file_path, 'r') as label_file:\n",
        "            class_id, x_center, y_center, width, height = map(float, label_file.readline().split())\n",
        "\n",
        "            # Random crop\n",
        "            random_cropped_img = random_crop(img)\n",
        "\n",
        "            # Augment the random cropped image\n",
        "            augmented_random_cropped_img = augment_image(random_cropped_img)\n",
        "\n",
        "            # Save the augmented random cropped image\n",
        "            cv2.imwrite(os.path.join(other_image_path, filename), cv2.cvtColor(np.array(augmented_random_cropped_img), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Save the label file for the other class\n",
        "            with open(os.path.join(other_label_path, label_filename), 'w') as other_label_file:\n",
        "                other_label_file.write('2')\n",
        "\n",
        "            # Extract object location\n",
        "            x_min, y_min, x_max, y_max = yolo_to_bbox(img.shape, class_id, x_center, y_center, width, height)\n",
        "\n",
        "            # Crop around the object\n",
        "            cropped_object_img = img[y_min:y_max, x_min:x_max]\n",
        "\n",
        "            # Resize to 32x32\n",
        "            resized_object_img = cv2.resize(cropped_object_img, (32, 32))\n",
        "\n",
        "            # Augment the resized object image\n",
        "            augmented_resized_object_img = augment_image(resized_object_img)\n",
        "\n",
        "            # Save the augmented resized object image\n",
        "            if class_id == 0:\n",
        "                cv2.imwrite(os.path.join(drone_image_path, filename), cv2.cvtColor(np.array(augmented_resized_object_img), cv2.COLOR_RGB2BGR))\n",
        "                with open(os.path.join(drone_label_path, label_filename), 'w') as drone_label_file:\n",
        "                    drone_label_file.write('0')\n",
        "            elif class_id == 1:\n",
        "                cv2.imwrite(os.path.join(bird_image_path, filename), cv2.cvtColor(np.array(augmented_resized_object_img), cv2.COLOR_RGB2BGR))\n",
        "                with open(os.path.join(bird_label_path, label_filename), 'w') as bird_label_file:\n",
        "                    bird_label_file.write('1')"
      ],
      "metadata": {
        "id": "VMtLSjSf6QrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/images')), len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/labels')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/images')), len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/labels')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/images')), len(os.listdir('/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/labels')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tX83LI0M9jK",
        "outputId": "7af2fe98-8ebb-4346-cdac-f050ca58b0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4070 4070\n",
            "1644 1644\n",
            "5714 5714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to TF Dataset\n",
        "## Prompt:\n",
        "Perfect. Now my images are in '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/images', '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/images' and '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/images'.\n",
        "My labels are in '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/other/labels',\n",
        "'/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/drone/labels' and '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/bird/labels'.\n",
        "\n",
        "\n",
        "I need you to convert all the files in those paths into one large TensorFlow dataset. Save the TensorFlow dataset in '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/', call it task7_DS. Ensure that the shapes and types of images and labels match TensorFlow's requirements.\n",
        "## Prompt 2:\n",
        "In the script you provided for converting the dataset into a tf dataset, on line - dataset = dataset.map(lambda x, y: (preprocess_image(x), preprocess_label(y)))\n",
        "I got the error - NotImplementedError: Cannot convert a symbolic tf.Tensor (StringToNumber:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported."
      ],
      "metadata": {
        "id": "FDbZcB7nscRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to read and preprocess an image\n",
        "def preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (32, 32))  # Ensure the image size is 32x32\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "    return img\n",
        "\n",
        "# Function to read and preprocess a label\n",
        "def preprocess_label(label_path):\n",
        "    def _preprocess_label(label_path):\n",
        "        label = tf.io.read_file(label_path)\n",
        "        label = tf.strings.to_number(tf.strings.split(label, '\\n')[0])\n",
        "        return label.numpy()  # Convert to numpy array\n",
        "\n",
        "    return tf.py_function(_preprocess_label, [label_path], tf.float32)\n",
        "\n",
        "# Get list of image and label paths\n",
        "other_image_paths = [os.path.join(other_image_path, img) for img in os.listdir(other_image_path) if img.endswith('.jpg')]\n",
        "drone_image_paths = [os.path.join(drone_image_path, img) for img in os.listdir(drone_image_path) if img.endswith('.jpg')]\n",
        "bird_image_paths = [os.path.join(bird_image_path, img) for img in os.listdir(bird_image_path) if img.endswith('.jpg')]\n",
        "\n",
        "other_label_paths = [os.path.join(other_label_path, label) for label in os.listdir(other_label_path) if label.endswith('.txt')]\n",
        "drone_label_paths = [os.path.join(drone_label_path, label) for label in os.listdir(drone_label_path) if label.endswith('.txt')]\n",
        "bird_label_paths = [os.path.join(bird_label_path, label) for label in os.listdir(bird_label_path) if label.endswith('.txt')]\n",
        "\n",
        "# Create TensorFlow dataset\n",
        "image_paths = other_image_paths + drone_image_paths + bird_image_paths\n",
        "label_paths = other_label_paths + drone_label_paths + bird_label_paths\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, label_paths))\n",
        "\n",
        "# Map the preprocess functions to the dataset\n",
        "dataset = dataset.map(lambda x, y: (preprocess_image(x), preprocess_label(y)))\n",
        "\n",
        "# Save the TensorFlow dataset\n",
        "tf.data.Dataset.save(dataset, '/content/drive/MyDrive/Learning/Road2_AI_Course/task7_ds/task7_DS')\n"
      ],
      "metadata": {
        "id": "3f6E1CjepY3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization and balance\n",
        "## Distribution and balance\n",
        "### Prompt:\n",
        "Perfect.\n",
        "I need you to visualize and display the dataset's class distribution (drone, bird and other). Also, I need you to print out if the dataset is balanced or not"
      ],
      "metadata": {
        "id": "ViwPf8XOsqdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to visualize class distribution\n",
        "def visualize_class_distribution(dataset):\n",
        "    class_counts = [0, 0, 0]  # Counts for 'other', 'drone', and 'bird'\n",
        "\n",
        "    for _, label in dataset:\n",
        "        class_index = tf.argmax(label).numpy()\n",
        "        class_counts[class_index] += 1\n",
        "\n",
        "    classes = ['Other', 'Drone', 'Bird']\n",
        "\n",
        "    # Plotting\n",
        "    plt.bar(classes, class_counts, color=['blue', 'green', 'red'])\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "# Visualize class distribution\n",
        "class_counts = visualize_class_distribution(dataset)\n",
        "\n",
        "# Check if the dataset is balanced\n",
        "is_balanced = all(count == class_counts[0] for count in class_counts[1:])\n",
        "print(f\"Is the dataset balanced? {'Yes' if is_balanced else 'No'}\")\n"
      ],
      "metadata": {
        "id": "6SvHhsGTsvus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showcasing 5 random images\n",
        "### Prompt:\n",
        "Great. now I need you to plot 5 random images from each class, just for showcase purpose"
      ],
      "metadata": {
        "id": "uZa5W1XatD-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function to display random images from each class\n",
        "def display_random_images(dataset, num_images=5):\n",
        "    classes = ['Other', 'Drone', 'Bird']\n",
        "    class_indices = {0: [], 1: [], 2: []}\n",
        "\n",
        "    # Collect indices of each class\n",
        "    for i, (_, label) in enumerate(dataset):\n",
        "        class_index = tf.argmax(label).numpy()\n",
        "        class_indices[class_index].append(i)\n",
        "\n",
        "    # Display random images from each class\n",
        "    for class_index, class_name in enumerate(classes):\n",
        "        print(f\"Random images from {class_name} class:\")\n",
        "        for _ in range(num_images):\n",
        "            random_index = random.choice(class_indices[class_index])\n",
        "            image, _ = dataset.skip(random_index).take(1).as_numpy_iterator().next()\n",
        "            plt.imshow(image)\n",
        "            plt.title(class_name)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "# Display random images\n",
        "display_random_images(dataset)\n"
      ],
      "metadata": {
        "id": "V3jE5f5BtDCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting DS into train and test\n",
        "### Prompt:\n",
        "Great. Now I need you to split our dataset into train and test sets"
      ],
      "metadata": {
        "id": "NG8N6eh9tlsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split dataset into train and test sets\n",
        "def split_dataset(dataset, train_percentage=0.8, seed=None):\n",
        "    # Get dataset size\n",
        "    dataset_size = len(dataset)\n",
        "    train_size = int(train_percentage * dataset_size)\n",
        "\n",
        "    # Set seed for reproducibility\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    dataset = dataset.shuffle(dataset_size, seed=seed)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    test_dataset = dataset.skip(train_size)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, test_dataset = split_dataset(dataset, train_percentage=0.8, seed=42)\n",
        "\n",
        "# Print the sizes of train and test sets\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "XI8_lfOztoDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and training the network\n",
        "## Model set up\n",
        "### Prompt:\n",
        "Perfect. Now it's time to use Keras and build a Convolutional Neural Network. Make sure the input layer has the right shape for our data, and make sure the output layer has 3 perceptrons (one for each possible class).\n",
        "### Prompt 2:\n",
        "Change it so that the input layer is already a Conv2D layer and don't forget the MaxPool layer after the input layer as well"
      ],
      "metadata": {
        "id": "WYUrm1Y6upkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Input layer with Conv2D and MaxPooling2D\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer with 3 perceptrons (for each class)\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "PQpyAQiTuoxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "### Prompt:\n",
        "Great. Now let's train this network on the dataset we have previously created. Print out the test accuracy when training is over"
      ],
      "metadata": {
        "id": "pAsgP8L8vXL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Convert the datasets to numpy arrays for compatibility with Keras\n",
        "train_images, train_labels = zip(*train_dataset.as_numpy_iterator())\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "test_images, test_labels = zip(*test_dataset.as_numpy_iterator())\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "MoG76p4IvWDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "## Plotting accuracy, loss and confusion matrix\n",
        "### Prompt:\n",
        "Perfect. Finally, let's plot the accuracy and loss graphs. Also, make sure to plot the confusion matrix"
      ],
      "metadata": {
        "id": "q8HVvVG-vsip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot accuracy and loss graphs\n",
        "def plot_accuracy_loss(history):\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm = cm / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# Convert one-hot encoded labels back to class indices\n",
        "test_predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "test_true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Plot accuracy and loss graphs\n",
        "plot_accuracy_loss(history)\n",
        "\n",
        "# Plot confusion matrix\n",
        "class_names = ['Other', 'Drone', 'Bird']\n",
        "plot_confusion_matrix(test_true_labels, test_predictions, class_names)\n"
      ],
      "metadata": {
        "id": "53NsLtowvuC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}